{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efcc03d3-9739-483c-b45c-0910c44ec8b2",
   "metadata": {},
   "source": [
    "# Set up environment\n",
    "This cell loads the libraries we need and sets environmentla variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3721b6b-509b-4d96-ad61-2fa7f15e87b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# set plotting theme/style\n",
    "sns.set(context='talk', style='white')\n",
    "\n",
    "# assign study-specific variables\n",
    "TR = 0.8 # in seconds\n",
    "\n",
    "project_dir = '/Users/catcamacho/Library/CloudStorage/Box-Box/CCP/HBN_study/Njenga_project/'\n",
    "out_dir = os.path.join(project_dir, 'DATA', 'processed_data')\n",
    "raw_dir = os.path.join(project_dir, 'DATA', 'raw_data')\n",
    "vid_dir = os.path.join(project_dir, 'DATA', 'video_data')\n",
    "sample_file = os.path.join(project_dir, 'DATA', 'helper_files','sample_gord.32k_fs_LR.pscalar.nii')\n",
    "\n",
    "# get parcel and network labels\n",
    "parcel_labels = nib.load(sample_file).header.get_axis(1).name\n",
    "network_labels = []\n",
    "for s in parcel_labels:\n",
    "    b = s.split('_')\n",
    "    if len(b)<2:\n",
    "        network_labels.append(b[0])\n",
    "    else:\n",
    "        network_labels.append(b[1])\n",
    "network_labels = np.array(network_labels)\n",
    "network_names, network_sizes = np.unique(network_labels, return_counts=True)\n",
    "\n",
    "# define measures of interest\n",
    "networks_of_interest = ['Auditory', 'CinguloOperc', 'Default', 'DorsalAttn', 'FrontoParietal',\n",
    "                        'SMhand', 'SMmouth', 'Salience', 'VentralAttn', 'Visual']\n",
    "\n",
    "vidfeat_of_interest = ['Positive','Negative','SpokenWords','Brightness',\n",
    "                       'SaliencyFract','Loudness']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80f9894-b7fe-431c-af55-97954f5f741d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Define functions\n",
    "These cells store custom functions used in our analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05208396-3eec-47b0-990f-def8a56d6d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile timeseries data\n",
    "def compile_ts_data(subdf, movie, datadir, outfile):\n",
    "    \"\"\"\n",
    "    combine timeseries data for each movie together into 1 file\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    subdf: DataFrame\n",
    "        A dataframe with subject IDs as the index. Includes IDs for all usable data.\n",
    "    movie: str\n",
    "        Corresponds with the str for the movie content to concatenate (e.g., \"DM\" or \"TP\").\n",
    "    datadir: folder path\n",
    "        Path to folder with the subject timeseries ciftis.\n",
    "    outfile: file path\n",
    "        Path including filename to save the output data of shape Ntimepoints x Nparcels x Nsubjects.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    data: numpy array\n",
    "        The compiled data of shape Ntimepoints x Nparcels x Nsubjects\n",
    "    \"\"\"\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    if not isinstance(subdf, pd.DataFrame):\n",
    "        subdf = pd.read_csv(subdf, index_col=0)\n",
    "    \n",
    "    for sub in subdf.index:\n",
    "        file = '{0}{1}_task-movie{2}_bold1_AP_Atlas_rescale_resid0.9_filt_gordonseitzman.32k_fs_LR.ptseries.nii'.format(datadir,sub, movie)\n",
    "        if sub == subdf.index[0]:\n",
    "            data = StandardScaler().fit_transform(nib.load(file).get_fdata())\n",
    "            data = np.expand_dims(data, axis=2)\n",
    "        else:\n",
    "            t = StandardScaler().fit_transform(nib.load(file).get_fdata())\n",
    "            t = np.expand_dims(t, axis=2)\n",
    "            data = np.concatenate([data,t],axis=2)\n",
    "    \n",
    "    print('Compile data from {0} brain regions measured at {1} timepoints from {2} participants.'.format(data.shape[1],data.shape[0],data.shape[2]))\n",
    "    np.save(outfile, data)\n",
    "    return(data)\n",
    "\n",
    "\n",
    "def compute_phase(group_ts_data, outfile):\n",
    "    \"\"\"\n",
    "    compute phase angles for each parcel timeseries\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    group_ts_data: filepath OR numpy array\n",
    "        File or numpy array with compiled timeseries data of shape Ntimepoints x Nparcels x Nsubjects \n",
    "        OR Ntimepoints x Nfeatures\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    phase_data: numpy array\n",
    "        The compiled data of shape Ntimepoints x Nparcels x Nsubjects\n",
    "    \"\"\"\n",
    "    from scipy.signal import hilbert\n",
    "    \n",
    "    if not isinstance(group_ts_data, np.ndarray):\n",
    "        group_ts_data = np.load(group_ts_data)\n",
    "    \n",
    "    phase_data = np.zeros_like(group_ts_data)\n",
    "    \n",
    "    if len(group_ts_data.shape)==3:\n",
    "        for a in range(0,group_ts_data.shape[1]):\n",
    "            for b in range(0,group_ts_data.shape[2]):\n",
    "                phase_data[:,a,b] = np.angle(hilbert(group_ts_data[:,a,b]), deg=False)\n",
    "    elif len(group_ts_data.shape)==2:\n",
    "        for a in range(0,group_ts_data.shape[1]):\n",
    "                phase_data[:,a] = np.angle(hilbert(group_ts_data[:,a]), deg=False)\n",
    "    \n",
    "    np.save(outfile, phase_data)\n",
    "    \n",
    "    return(phase_data)\n",
    "\n",
    "\n",
    "\n",
    "def compute_ips(group_phase_data, outprefix, intersub=True, interregion=False, savemean=True):\n",
    "    \"\"\"\n",
    "    parcel-wise inter-subject phase synchrony- output pairwise IPS and mean global IPS\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    group_phase_data: numpy array\n",
    "        The compiled data of shape Ntimepoints x Nparcels x Nsubjects\n",
    "    outprefix: string\n",
    "        The filepath and file prefix for the saved IPS data.\n",
    "    intersub: bool\n",
    "        Set to True to compute intersubject phase synchrony.  Set to False for inter-region.\n",
    "    interregion: bool\n",
    "        Set to True to computer inter-region instantaneous phase synchrony. Set to False for intersubject. \n",
    "    savemean: bool\n",
    "        Set to True to save average IPS (across subjects)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    ips_data: numpy array\n",
    "        Instantaneous phase synchrony data of shape Nparcels x Nsubjects x Nsubjects x Ntimepoints \n",
    "        OR Nsubjects x Nparcels x Nparcels x Ntimepoints\n",
    "    mean_ips_data: numpy array\n",
    "        Instantaneous phase synchrony data, averaged across time, of shape Nparcels x Ntimepoints\n",
    "        \n",
    "    \"\"\"\n",
    "    import itertools\n",
    "    \n",
    "    if not isinstance(group_phase_data, np.ndarray):\n",
    "        group_phase_data = np.load(group_phase_data)\n",
    "    \n",
    "        \n",
    "    if intersub:\n",
    "        if os.path.isdir(outprefix):\n",
    "            file_name = os.path.join(outprefix, 'ips_data.dat')\n",
    "        else:\n",
    "            file_name = outprefix + 'ips_data.dat'\n",
    "        ips_data = np.empty(file_name, dtype=np.float32, mode='w+',\n",
    "                              shape=(group_phase_data.shape[1],\n",
    "                                     group_phase_data.shape[2],\n",
    "                                     group_phase_data.shape[2],\n",
    "                                     group_phase_data.shape[0]))\n",
    "\n",
    "        subs = range(0, group_phase_data.shape[2])\n",
    "        for region in range(0, group_phase_data.shape[1]):\n",
    "            combs = itertools.combinations(subs, 2)\n",
    "            for c in combs:\n",
    "                sub1 = group_phase_data[:, region, c[0]]\n",
    "                sub2 = group_phase_data[:, region, c[1]]\n",
    "                a = 1 - np.sin(np.abs(sub1 - sub2) / 2)\n",
    "                ips_data[region,c[0],c[1],:] = a\n",
    "                ips_data[region,c[1],c[0],:] = a\n",
    "\n",
    "        if savemean:\n",
    "            mask = np.tri(ips_data.shape[2], ips_data.shape[2], -1, dtype=int)\n",
    "            mean_ips_data = np.mean(ips_data[:,mask==1,:], axis=1)\n",
    "            if os.path.isdir(outprefix):\n",
    "                mean_file_name = os.path.join(outprefix, 'mean_isps_data.npy')\n",
    "            else:\n",
    "                mean_file_name = outprefix + 'mean_isps_data.npy'\n",
    "            np.save(mean_file_name, mean_ips_data.T)\n",
    "            return(mean_ips_data, ips_data)\n",
    "        else:\n",
    "            return(ips_data)\n",
    "        \n",
    "    if interregion:\n",
    "        if os.path.isdir(outprefix):\n",
    "            file_name = os.path.join(outprefix, 'ips_data.npy')\n",
    "        else:\n",
    "            file_name = outprefix + 'ips_data.npy'\n",
    "        ips_data = np.empty((group_phase_data.shape[2],\n",
    "                             group_phase_data.shape[1],\n",
    "                             group_phase_data.shape[1],\n",
    "                             group_phase_data.shape[0]))\n",
    "\n",
    "        regions = range(0, group_phase_data.shape[1])\n",
    "        for sub in range(0, group_phase_data.shape[2]):\n",
    "            combs = itertools.combinations(regions, 2)\n",
    "            for c in combs:\n",
    "                sub1 = group_phase_data[:, c[0], sub]\n",
    "                sub2 = group_phase_data[:, c[1], sub]\n",
    "                a = 1 - np.sin(np.abs(sub1 - sub2) / 2)\n",
    "                ips_data[sub,c[0],c[1],:] = a\n",
    "                ips_data[sub,c[1],c[0],:] = a\n",
    "        np.save(file_name, ips_data)\n",
    "        \n",
    "        if savemean:\n",
    "            mean_ips_data = np.mean(ips_data, axis=0)\n",
    "            if os.path.isdir(outprefix):\n",
    "                mean_file_name = os.path.join(outprefix, 'mean_isps_data.npy')\n",
    "            else:\n",
    "                mean_file_name = outprefix + 'mean_isps_data.npy'\n",
    "\n",
    "            np.save(mean_file_name, mean_ips_data.T)\n",
    "            return(mean_ips_data, ips_data)\n",
    "        else:\n",
    "            return(ips_data)\n",
    "\n",
    "        \n",
    "        \n",
    "def brain_bx_crosscorr(brain, bx):\n",
    "    \"\"\"\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    brain: numpy array\n",
    "        neural phase data of shape Nsubjects x Nparcels x Nparcels x Ntimepoints\n",
    "    bx: numpy array\n",
    "        Nfeatures x Ntimepoints\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    cross_corr: numpy array\n",
    "        \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    cross_corr = np.empty([brain.shape[0], brain.shape[1], brain.shape[2], bx.shape[1]])\n",
    "\n",
    "    # compute lags\n",
    "    for sub in range(0, brain.shape[0]):\n",
    "        for n1 in range(0, brain.shape[1]):\n",
    "            for n2 in range(0, brain.shape[1]):\n",
    "                if n1!=n2:\n",
    "                    for b in range(0, bx.shape[1]):\n",
    "                        res = correlate(brain[sub, n1, n2, :], bx[:,b], mode='same')\n",
    "                        lags = correlation_lags(brain[sub, n1, n2, :].shape[0], bx[:,b].shape[0], mode='same')\n",
    "                        cross_corr[sub, n1, n2, b] = lags[np.argmax(res)]\n",
    "                        cross_corr[sub, n2, n1, b] = lags[np.argmax(res)]\n",
    "    \n",
    "    return(cross_corr)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aade7af1-a111-4343-8ddb-5d373e8375e8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Analysis\n",
    "These cells perform the following analysis steps:\n",
    "1. Compute inter- and intra-network dynamic connectivity\n",
    "2. Test synchronization with emotion ratings\n",
    "3. Compute lagged synchronization with emotion ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cfaab7-b19b-4035-90a1-045b88b78981",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Compute inter- and intra-network dynamic connectivity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0206b0-26b3-401b-a77c-19e8ae96530a",
   "metadata": {},
   "source": [
    "### prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727c57de-a345-4876-a75e-a9a18ab00203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in raw fMRI timeseries data\n",
    "tseries = np.load(os.path.join(raw_dir, 'compiled_ts_data_movieDM.npy'))\n",
    "\n",
    "# Convert to phase angles and save data\n",
    "phasefile = os.path.join(out_dir, 'phase_data_movieDM.npy')\n",
    "phase = compute_phase(tseries, outfile)\n",
    "\n",
    "print(phase.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3075a65b-08a1-4b3c-bf0f-5133a1fb48c4",
   "metadata": {},
   "source": [
    "### compute intra-network dynamic connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5f9a8d-e171-4606-8016-b5dee8fa8dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average within networks\n",
    "net_phase = np.empty([phase.shape[0],len(networks_of_interest), phase.shape[2]])\n",
    "for i, net in enumerate(networks_of_interest):\n",
    "    net_phase[:, i, :] = np.mean(phase[:, network_labels==net, :], axis=1)\n",
    "\n",
    "# compute pair-wise network dynamic connectivity\n",
    "outprefix = os.path.join(out_dir, 'between_networks_movieDM_')\n",
    "mean_ips, ips = compute_ips(net_phase, outprefix, intersub=False, interregion=True, savemean=True)\n",
    "\n",
    "# plot group mean\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i, net in enumerate(networks_of_interest):\n",
    "    if i!=2:\n",
    "        plt.plot(mean_ips[2, i, :], label=net)\n",
    "    plt.xlim(0,750)\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03612932-3afb-41c3-8ebe-f748c0fc57ba",
   "metadata": {},
   "source": [
    "### compute inter-network dynamic connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8442be61-03b9-4ba4-b1cf-4b00124b41cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take phase angle data and compute Default dynamic connectivity\n",
    "\n",
    "\n",
    "# average within default mode network parcels\n",
    "\n",
    "\n",
    "# plot group mean\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2fc0d0-a3e0-4e57-8d8d-73e463f36fa8",
   "metadata": {},
   "source": [
    "## 2. Test instantaneous synchronization between ratings and connectivity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952506bd-edc8-4c19-be6d-be6bb78e80d6",
   "metadata": {},
   "source": [
    "### prepare video ratings data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd5f8c2-225d-4c48-b85f-4ab90f1efbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "video_features_file = os.path.join(vid_dir, 'DM_summary_codes_intuitivenames.csv')\n",
    "features = pd.read_csv(video_features_file, index_col=0).loc[:, vidfeat_of_interest]\n",
    "\n",
    "# rescale to 0 to 1\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "features.loc[:,:] = MinMaxScaler().fit_transform(features.to_numpy())\n",
    "\n",
    "# time shift to account for hemodynamic delay (5 samples)\n",
    "from emocodes.analysis.features import hrf_convolve_features\n",
    "hrf_features = hrf_convolve_features(features, units='s')\n",
    "\n",
    "# save data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537bc4d6-0c71-45d6-aaf1-49872e1ea9a3",
   "metadata": {},
   "source": [
    "### compute IPS between each video feature and dynamic connectivity metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eaa19b7-1c47-4fdd-b92b-ff321f443ef9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
